{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd02471cdaf8db7a966e7922cbb886a7ed46f4c32e5930b845a9816621b044b7db3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2471cdaf8db7a966e7922cbb886a7ed46f4c32e5930b845a9816621b044b7db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mitdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of patients\n",
    "pts = ['100','101','102','103','104','105','106','107',\n",
    "       '108','109','111','112','113','114','115','116',\n",
    "       '117','118','119','121','122','123','124','200',\n",
    "       '201','202','203','205','207','208','209','210',\n",
    "       '212','213','214','215','217','219','220','221',\n",
    "       '222','223','228','230','231','232','233','234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for pt in pts:\n",
    "    file = data_path + pt\n",
    "    \n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    sym = annotation.symbol\n",
    "    \n",
    "    values, counts = np.unique(sym, return_counts=True)\n",
    "    df_sub = pd.DataFrame({'sym':values, 'val':counts, 'pt':[pt]*len(counts)})\n",
    "    df = pd.concat([df, df_sub],axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sym\n",
       "N    75052\n",
       "L     8075\n",
       "R     7259\n",
       "V     7130\n",
       "/     7028\n",
       "A     2546\n",
       "+     1291\n",
       "f      982\n",
       "F      803\n",
       "~      616\n",
       "!      472\n",
       "\"      437\n",
       "j      229\n",
       "x      193\n",
       "a      150\n",
       "|      132\n",
       "E      106\n",
       "J       83\n",
       "Q       33\n",
       "e       16\n",
       "[        6\n",
       "]        6\n",
       "S        2\n",
       "Name: val, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.groupby('sym').val.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of nonbeat and abnormal\n",
    "nonbeat = ['[','!',']','x','(',')','p','t','u','`',\n",
    "           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n",
    "abnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into normal, abnormal or nonbeat\n",
    "df['cat'] = -1\n",
    "df.loc[df.sym == 'N','cat'] = 0\n",
    "df.loc[df.sym.isin(abnormal), 'cat'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cat\n",
       "-1     3186\n",
       " 0    75052\n",
       " 1    34409\n",
       "Name: val, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.groupby('cat').val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function for loading a single patient's signals and annotations\n",
    "def load_ecg(file):\n",
    "    # load the ecg\n",
    "    # example file: 'mit-bih-arrhythmia-database-1.0.0/101'\n",
    "    \n",
    "    # load the ecg\n",
    "    record = wfdb.rdrecord(file)\n",
    "    # load the annotation\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    \n",
    "    # extract the signal\n",
    "    p_signal = record.p_signal\n",
    "    \n",
    "    # verify frequency is 360\n",
    "    assert record.fs == 360, 'sample freq is not 360'\n",
    "    \n",
    "    # extract symbols and annotation index\n",
    "    atr_sym = annotation.symbol\n",
    "    atr_sample = annotation.sample\n",
    "    \n",
    "    return p_signal, atr_sym, atr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = data_path + pts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling a function\n",
    "p_signal, atr_sym, atr_sample = load_ecg(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+ 3\nJ 50\nN 2700\nV 3\n~ 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "values, counts = np.unique(sym, return_counts=True)\n",
    "for v,c in zip(values, counts):\n",
    "    print(v,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2044, 66792, 74986, 99579, 128085, 170719, 279576, 305709, 307745, 312825]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# get abnormal beat index\n",
    "ab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\n",
    "ab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(p_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sec = 3\n",
    "fs = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36 12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed( 42 )\n",
    "pts_train = random.sample(pts, 36)\n",
    "pts_valid = [pt for pt in pts if pt not in pts_train]\n",
    "print(len(pts_train), len(pts_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80614, 2160) (80614, 1) 80614\n(28485, 2160) (28485, 1) 28485\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, sym_train = make_dataset(pts_train, num_sec, fs, abnormal)\n",
    "X_valid, y_valid, sym_valid = make_dataset(pts_valid, num_sec, fs, abnormal)\n",
    "print(X_train.shape, y_train.shape, len(sym_train))\n",
    "print(X_valid.shape, y_valid.shape, len(sym_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "2520/2520 [==============================] - 22s 3ms/step - loss: 0.3113 - accuracy: 0.8784\n",
      "Epoch 2/5\n",
      "2520/2520 [==============================] - 4s 1ms/step - loss: 0.1479 - accuracy: 0.9552\n",
      "Epoch 3/5\n",
      "2520/2520 [==============================] - 3s 1ms/step - loss: 0.1268 - accuracy: 0.9630\n",
      "Epoch 4/5\n",
      "2520/2520 [==============================] - 3s 1ms/step - loss: 0.1169 - accuracy: 0.9663\n",
      "Epoch 5/5\n",
      "2520/2520 [==============================] - 3s 1ms/step - loss: 0.1111 - accuracy: 0.9677\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c8f282190>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(\n",
    "                loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs= 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2520/2520 [==============================] - 5s 2ms/step\n",
      "891/891 [==============================] - 1s 821us/step\n"
     ]
    }
   ],
   "source": [
    "y_train_preds_dense = model.predict(X_train,verbose = 1)\n",
    "y_valid_preds_dense = model.predict(X_valid,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.29906715955045027"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "thresh = (sum(y_train)/len(y_train))[0]\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "def calc_prevalence(y_actual):\n",
    "    return (sum(y_actual)/len(y_actual))\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train\n",
      "AUC:0.993\n",
      "accuracy:0.977\n",
      "recall:0.951\n",
      "precision:0.973\n",
      "specificity:0.989\n",
      "prevalence:0.299\n",
      " \n",
      "Valid\n",
      "AUC:0.849\n",
      "accuracy:0.746\n",
      "recall:0.354\n",
      "precision:0.850\n",
      "specificity:0.965\n",
      "prevalence:0.358\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Train');\n",
    "print_report(y_train, y_train_preds_dense, thresh)\n",
    "print('Valid');\n",
    "print_report(y_valid, y_valid_preds_dense, thresh);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80614, 2160, 1)\n(28485, 2160, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN- Classification using \n",
    "\n",
    "# reshape input to be [samples, time steps, features = 1]\n",
    "X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n",
    "\n",
    "print(X_train_cnn.shape)\n",
    "print(X_valid_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(\n",
    "                loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "2520/2520 [==============================] - 688s 271ms/step - loss: 0.2716 - accuracy: 0.9001\n",
      "Epoch 2/3\n",
      "2520/2520 [==============================] - 656s 260ms/step - loss: 0.1237 - accuracy: 0.9635\n",
      "Epoch 3/3\n",
      "2520/2520 [==============================] - 630s 250ms/step - loss: 0.0917 - accuracy: 0.9716\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c8f217160>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "model.fit(X_train_cnn, y_train, batch_size = 32, epochs= 3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2520/2520 [==============================] - 105s 41ms/step\n",
      "891/891 [==============================] - 38s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train\n",
      "AUC:0.994\n",
      "accuracy:0.963\n",
      "recall:0.976\n",
      "precision:0.906\n",
      "specificity:0.957\n",
      "prevalence:0.299\n",
      " \n",
      "Valid\n",
      "AUC:0.898\n",
      "accuracy:0.803\n",
      "recall:0.854\n",
      "precision:0.679\n",
      "specificity:0.775\n",
      "prevalence:0.358\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('Train');\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid');\n",
    "print_report(y_valid, y_valid_preds_cnn, thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}